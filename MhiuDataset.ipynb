{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It generates the dataset for mhui\n",
    "# You need all data in the:\n",
    "#     ./data/mhui/images\n",
    "#     ./data/mhui/groundtruth\n",
    "# It will crop the white parts and put the files in\n",
    "#     ./data/mhui/cropped/images\n",
    "#     ./data/mhui/cropped/groundtruth\n",
    "# It will create the patches in:\n",
    "#     ./data/mhui/generate/patches_rotation/images/\n",
    "#     ./data/mhui/generate/patches_rotation/groundtruth/\n",
    "# It will calculate the distances\n",
    "#     ./data/mhui/generate/patches_rotation/distance/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess # subprocess.call(['./test.sh'])\n",
    "import os\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage, misc, stats\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 1\n",
    "CURRENT_DIR = './data/mhui/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cropp the white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_rows(original_image, original_groundtruth):\n",
    "    width = original_image.shape[0]\n",
    "    length = original_image.shape[1]\n",
    "    for i in range(width):\n",
    "        white_pixels_count = 0\n",
    "        for j in range(length):\n",
    "            if np.all(original_image[i][j] == 255):\n",
    "                white_pixels_count = white_pixels_count + 1\n",
    "        if white_pixels_count < THRESHOLD:\n",
    "            break\n",
    "    row_top = i\n",
    "\n",
    "    for i in range(width):\n",
    "        white_pixels_count = 0\n",
    "        for j in range(length):\n",
    "            if np.all(original_image[width - i - 1][j] == 255):\n",
    "                white_pixels_count = white_pixels_count + 1\n",
    "        if white_pixels_count < THRESHOLD:\n",
    "            break\n",
    "    row_bottom = width - i - 1        \n",
    "\n",
    "    return original_image[row_top:row_bottom, :], original_groundtruth[row_top:row_bottom, :]\n",
    "\n",
    "def crop_columns(original_image, original_groundtruth):\n",
    "    width = original_image.shape[0]\n",
    "    length = original_image.shape[1]\n",
    "\n",
    "    for j in range(length):\n",
    "        white_pixels_count = 0\n",
    "        for i in range(width):\n",
    "            if np.all(original_image[i][j] == 255):\n",
    "                white_pixels_count = white_pixels_count + 1\n",
    "        if white_pixels_count < THRESHOLD:\n",
    "             break;        \n",
    "    column_left = j\n",
    "\n",
    "    for j in range(length):\n",
    "        white_pixels_count = 0\n",
    "        for i in range(width):\n",
    "            if np.all(original_image[i][length - j -1] == 255):\n",
    "                white_pixels_count = white_pixels_count + 1\n",
    "        if white_pixels_count < THRESHOLD:\n",
    "            break\n",
    "    column_right = length - j - 1\n",
    "\n",
    "    return original_image[:, column_left:column_right], original_groundtruth[:, column_left:column_right]\n",
    "\n",
    "def crop_white_area(path, image_name):\n",
    "    global index_cropping\n",
    "    try:\n",
    "        name = image_name.split(\".\")\n",
    "        groundtruth_name = str(name[0]) + \".tif\"\n",
    "        img_org = Image.open(path + \"/images/\" + image_name)\n",
    "        groundtruth_org = Image.open(path + \"/groundtruth/\" + groundtruth_name)\n",
    "        groundtruth_org = groundtruth_org.convert('L')\n",
    "        original_image = np.asarray(img_org)\n",
    "        original_groundtruth = np.asarray(groundtruth_org)\n",
    "\n",
    "        max_white_row_top = 0\n",
    "        for j in range(original_image.shape[1]):\n",
    "            if np.all(original_image[0][j] == 255):\n",
    "                max_white_row_top = max_white_row_top + 1\n",
    "        max_white_row_bottom = 0\n",
    "        for j in range(original_image.shape[1]):\n",
    "            if np.all(original_image[original_image.shape[0] - 1][j] == 255):\n",
    "                max_white_row_bottom = max_white_row_bottom + 1 \n",
    "        max_row = max(max_white_row_top, max_white_row_bottom)\n",
    "\n",
    "        max_white_column_left = 0;\n",
    "        for i in range(original_image.shape[0]):\n",
    "            if np.all(original_image[i][0] == 255):\n",
    "                max_white_column_left = max_white_column_left + 1\n",
    "        max_white_column_right = 0;\n",
    "        for i in range(original_image.shape[0]):\n",
    "            if np.all(original_image[i][original_image.shape[1] - 1] == 255):\n",
    "                max_white_column_right = max_white_column_right + 1\n",
    "        max_column = max(max_white_column_left, max_white_column_right)\n",
    "\n",
    "\n",
    "        if (max_row >= max_column):\n",
    "            #print(\"Rows first!\")\n",
    "            cropped_image_rows, cropped_groundtruth_rows = crop_rows(original_image, original_groundtruth)\n",
    "            cropped_image, cropped_groundtruth = crop_columns(cropped_image_rows, cropped_groundtruth_rows)\n",
    "        else:\n",
    "            #print(\"Columns first!\")\n",
    "            cropped_image_columns, cropped_groundtruth_columns = crop_columns(original_image, original_groundtruth)\n",
    "            cropped_image, cropped_groundtruth = crop_rows(cropped_image_columns, cropped_groundtruth_columns)\n",
    "\n",
    "        image = Image.fromarray(cropped_image, 'RGB')\n",
    "        groundtruth = Image.fromarray(cropped_groundtruth, 'L')\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        #save image\n",
    "        image.save(path + \"/cropped/images/\" + image_name)\n",
    "        groundtruth.save(path + \"/cropped/groundtruth/\" + groundtruth_name)\n",
    "        index_cropping += 1\n",
    "        #image.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1109 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/mhui/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1109/1109 [1:24:06<00:00,  8.93s/it]\n"
     ]
    }
   ],
   "source": [
    "index_cropping = 0\n",
    "print(CURRENT_DIR)\n",
    "\n",
    "if not os.path.exists(CURRENT_DIR + \"cropped\"):\n",
    "    os.makedirs(CURRENT_DIR + \"cropped\")\n",
    "if not os.path.exists(CURRENT_DIR + \"cropped/images\"):\n",
    "    os.makedirs(CURRENT_DIR + \"cropped/images\")\n",
    "if not os.path.exists(CURRENT_DIR + \"cropped/groundtruth\"):\n",
    "    os.makedirs(CURRENT_DIR + \"cropped/groundtruth\") \n",
    "\n",
    "original_path = CURRENT_DIR + \"/images/\"\n",
    "for f in tqdm(listdir(original_path)):\n",
    "    if f.endswith(\".tiff\"):\n",
    "        crop_white_area(CURRENT_DIR, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patch_size = 200\n",
    "index = 0\n",
    "\n",
    "def generate_images(groundtruth_dir, image_dir, image_name, output_dir, patch_size):\n",
    "    global index\n",
    "    \n",
    "    name = image_name.split(\".\")\n",
    "    groundtruth_name = str(name[0]) + \".tif\"\n",
    "    \n",
    "    image_path = images_dir + image_name\n",
    "    ground_t_path = ground_t_dir + groundtruth_name\n",
    "    \n",
    "    img_org = ndimage.imread(ground_t_path, mode='L')\n",
    "    img_sat = ndimage.imread(image_path)\n",
    "    shape = img_org.shape\n",
    "    \n",
    "    for l in range(0, shape[0]-patch_size, patch_size):\n",
    "        for r in range(0, shape[1]-patch_size, patch_size):\n",
    "        \n",
    "            patch_org = img_org[l:(l+patch_size), r:(r+patch_size)]\n",
    "            patch_sat = img_sat[l:(l+patch_size), r:(r+patch_size)]\n",
    "\n",
    "            org_name = '{}groundtruth/{}_{}.png'.format(output_dir,name[0], str(index).zfill(5))\n",
    "            sat_name = '{}images/{}_{}.png'.format(output_dir,name[0], str(index).zfill(5))\n",
    "\n",
    "            rotation  = np.random.randint(0,4)\n",
    "            patch_org = np.rot90(patch_org, rotation)\n",
    "            patch_sat = np.rot90(patch_sat, rotation)\n",
    "\n",
    "            #print(org_name)\n",
    "            if patch_org.shape == (patch_size, patch_size):\n",
    "                misc.imsave(org_name, patch_org)\n",
    "                misc.imsave(sat_name, patch_sat)\n",
    "            index += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [13:56<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "ground_t_dir = CURRENT_DIR + 'cropped/groundtruth/'\n",
    "images_dir   = CURRENT_DIR + 'cropped/images/'\n",
    "output_dir   = '{}/generate/patches_rotation/'.format(CURRENT_DIR)\n",
    "\n",
    "if not os.path.exists(output_dir+'groundtruth'):\n",
    "    os.makedirs(output_dir+'groundtruth')\n",
    "if not os.path.exists(output_dir+'images'):\n",
    "    os.makedirs(output_dir+'images')\n",
    "\n",
    "for file in tqdm(listdir(images_dir)):\n",
    "    generate_images(images_dir, ground_t_dir, file, output_dir, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closest_node(node, nodes):\n",
    "    nodes = np.asarray(nodes)\n",
    "    dist_2 = np.sum((nodes - node)**2, axis=1)\n",
    "    return np.argmin(dist_2)\n",
    "\n",
    "def save_distances(input_path, output_path, img_name):\n",
    "    global index_distance\n",
    "    \n",
    "    img_org = ndimage.imread(input_path+img_name, mode='L')\n",
    "    img_org[img_org < 127] = 0\n",
    "    img_org[img_org >= 127] = 255\n",
    "    road_pxs     = np.argwhere(img_org != 0)\n",
    "    non_road_pxs = np.argwhere(img_org == 0)\n",
    "    output = np.zeros(img_org.shape, dtype=np.int)\n",
    "    if len(road_pxs) == 0:\n",
    "        return\n",
    "    for coord in non_road_pxs:\n",
    "        closest_px = road_pxs[closest_node(coord, road_pxs)]\n",
    "        output[tuple(coord)] = (coord[0]-closest_px[0])**2 + (coord[1]-closest_px[1])**2\n",
    "    \n",
    "    misc.imsave(output_path+img_name, output)\n",
    "    index_distance += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 23103/43505 [5:39:59<8:10:40,  1.44s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7938267be7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msave_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e8feab6e0c47>\u001b[0m in \u001b[0;36msave_distances\u001b[0;34m(input_path, output_path, img_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcoord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_road_pxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mclosest_px\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroad_pxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclosest_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroad_pxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclosest_px\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclosest_px\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e8feab6e0c47>\u001b[0m in \u001b[0;36mclosest_node\u001b[0;34m(node, nodes)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdist_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index_distance = 0\n",
    "input_path   = '{}/generate/patches_rotation/groundtruth/'.format(CURRENT_DIR)\n",
    "output_path   = '{}/generate/patches_rotation/distance/'.format(CURRENT_DIR)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "for f in tqdm(listdir(input_path)[1:]):\n",
    "    save_distances(input_path, output_path, f)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
